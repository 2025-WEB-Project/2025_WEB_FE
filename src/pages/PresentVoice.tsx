import React, { useEffect, useState, useRef } from "react";

const SpeechRecognition: typeof window.SpeechRecognition | undefined =
  (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;

interface VoiceMetrics {
  wpm: number; // Words per minute
  volumeMean: number;
  volumeStability: number;
  silenceRatio: number;
}

interface VolumeSample {
  db: number;
  time: number;
}

const PresentVoice: React.FC = () => {
  const [text, setText] = useState("");
  const [isListening, setIsListening] = useState(false);
  const [metrics, setMetrics] = useState<VoiceMetrics | null>(null);

  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const dataArrayRef = useRef<Float32Array | null>(null);

  // ë‹¨ì–´ ìˆ˜ ê³„ì‚°ìš©
  const wordCountRef = useRef(0);
  const startTimeRef = useRef<number | null>(null);

  // ìŒëŸ‰ ì•ˆì •ì„± ê³„ì‚° ê°„ê²©
  const lastStabilityUpdateRef = useRef<number>(0);

  // ğŸ¤ ìŒì„± ì¸ì‹ ì‹œì‘
  const startListening = () => {
    if (!SpeechRecognition) {
      alert("ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = "ko-KR";
    recognition.continuous = true;
    recognition.interimResults = true;

    recognition.onresult = (event: SpeechRecognitionEvent) => {
      const transcript = Array.from(event.results)
        .map((r) => r[0].transcript)
        .join("");
      setText(transcript);

      const words = transcript.trim().split(/\s+/).filter((w) => w.length > 0);
      wordCountRef.current = words.length;

      if (!startTimeRef.current) startTimeRef.current = Date.now();
      const elapsedMin = (Date.now() - startTimeRef.current) / 60000;
      const wpm = words.length / Math.max(elapsedMin, 0.01);

      setMetrics((prev) => ({
        ...(prev || {
          volumeMean: 0,
          volumeStability: 0,
          silenceRatio: 0,
        }),
        wpm,
      }));
    };

    recognition.onend = () => {
      setIsListening(false);
    };

    recognition.start();
    setIsListening(true);
  };

  const stopListening = () => {
    setIsListening(false);
    audioContextRef.current?.close();
  };

  // ğŸšï¸ ìŒí–¥ ë¶„ì„ (ì‹¤ì‹œê°„)
  useEffect(() => {
    if (!isListening) return;

    let audioCtx: AudioContext;
    let source: MediaStreamAudioSourceNode;
    let animationId: number;
    let silenceCount = 0;
    let frame = 0;
    const volumeHistory: VolumeSample[] = [];

    (async () => {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      audioCtx = new (window.AudioContext ||
        (window as any).webkitAudioContext)();
      source = audioCtx.createMediaStreamSource(stream);

      const analyser = audioCtx.createAnalyser();
      analyser.fftSize = 2048;
      const dataArray = new Float32Array(analyser.fftSize);

      audioContextRef.current = audioCtx;
      analyserRef.current = analyser;
      dataArrayRef.current = dataArray;
      source.connect(analyser);

      const detectMetrics = () => {
        analyser.getFloatTimeDomainData(dataArray);
        frame++;

        // RMS ê³„ì‚°
        const rms = Math.sqrt(
          dataArray.reduce((sum, x) => sum + x * x, 0) / dataArray.length
        );
        const db = 20 * Math.log10(rms + 1e-8);

        // --- [ì‹¤ì‹œê°„ í‰ê· ] ---
        volumeHistory.push({ db, time: Date.now() });
        if (volumeHistory.length > 1800) volumeHistory.shift(); // ì•½ 30ì´ˆ (60fps * 30ì´ˆ)

        // í‰ê·  ìŒëŸ‰ (ìµœê·¼ 1ì´ˆ)
        const recent1s = volumeHistory.filter(
          (v) => Date.now() - v.time < 1000
        );
        const mean =
          recent1s.reduce((a, b) => a + b.db, 0) /
          Math.max(recent1s.length, 1);

        // ì¹¨ë¬µ ê°ì§€
        const silenceThreshold = -55;
        if (db < silenceThreshold) silenceCount++;

        const silenceRatio = Math.min(100, (silenceCount / frame) * 100);

        // --- [ìŒëŸ‰ ì•ˆì •ì„±: 10ì´ˆ ë‹¨ìœ„ë¡œë§Œ ê°±ì‹ ] ---
        let longStd = metrics?.volumeStability ?? 0;
        const now = Date.now();
        if (now - lastStabilityUpdateRef.current >= 10000) {
          const longWindow = volumeHistory.map((v) => v.db);
          const longMean =
            longWindow.reduce((a, b) => a + b, 0) /
            Math.max(longWindow.length, 1);
          const longVar =
            longWindow.reduce((s, x) => s + (x - longMean) ** 2, 0) /
            Math.max(longWindow.length, 1);
          longStd = Math.sqrt(longVar);
          lastStabilityUpdateRef.current = now;
        }

        // ğŸ’¡ ì‹¤ì‹œê°„ ê°±ì‹ 
        setMetrics((prev) => ({
          ...(prev || { wpm: 0 }),
          volumeMean: mean,
          volumeStability: longStd,
          silenceRatio,
        }));

        animationId = requestAnimationFrame(detectMetrics);
      };

      detectMetrics();
    })();

    return () => {
      cancelAnimationFrame(animationId);
      audioContextRef.current?.close();
    };
  }, [isListening]);

  return (
    <div style={{ padding: "20px", fontFamily: "Pretendard", lineHeight: 1.6 }}>
      <h2>ğŸ™ï¸ ì‹¤ì‹œê°„ ë§í•˜ê¸° ë¶„ì„</h2>

      <button
        onClick={isListening ? stopListening : startListening}
        style={{
          background: isListening ? "#FF5050" : "#007BFF",
          color: "#fff",
          padding: "10px 20px",
          borderRadius: "6px",
          border: "none",
          cursor: "pointer",
          marginBottom: "15px",
        }}
      >
        {isListening ? "ğŸ›‘ ì¤‘ì§€" : "ğŸ¤ ì‹œì‘"}
      </button>

      <div
        style={{
          padding: "15px",
          background: "#f9f9f9",
          borderRadius: "8px",
          border: "1px solid #ddd",
          minHeight: "100px",
        }}
      >
        <b>ğŸ—£ï¸ ì¸ì‹ëœ ë§:</b>
        <p style={{ marginTop: "10px", color: "#333" }}>{text || "..."}</p>
      </div>

      {metrics && (
        <div style={{ marginTop: "25px" }}>
          <h3>ğŸ“Š ì‹¤ì‹œê°„ ìŒì„± ì§€í‘œ</h3>
          <ul>
            <li>
              <b>ë§ì†ë„ (WPM):</b> {metrics.wpm.toFixed(1)} ë‹¨ì–´/ë¶„
            </li>
            <li>
              <b>ìŒëŸ‰ ì•ˆì •ì„± (10ì´ˆ ë‹¨ìœ„):</b> Â±{metrics.volumeStability.toFixed(2)} dB
            </li>
            <li>
              <b>ì¹¨ë¬µ ë¹„ìœ¨:</b> {metrics.silenceRatio.toFixed(1)} %
            </li>
          </ul>
        </div>
      )}
    </div>
  );
};

export default PresentVoice;
